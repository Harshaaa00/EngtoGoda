{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio faster-whisper translate python-dotenv elevenlabs requests"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XikhvRE3M-Qc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voice-to-Voice Translation System  \n",
        "### English ‚Üí Multi-Language + Godavari Telugu (Offline TTS)\n",
        "\n",
        "**Project Track:** Applied AI / NLP / Speech Processing  \n",
        "**Author:** Boddu Harshavardhan\n"
      ],
      "metadata": {
        "id": "IsrG7GVROSTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Problem Definition & Objective\n",
        "\n",
        "Language barriers remain a major challenge in communication, especially for regional dialects and informal speech.\n",
        "While text translation systems exist, **voice-to-voice translation for dialect-specific languages** is still limited.\n",
        "\n",
        "### Objective\n",
        "The objective of this project is to design and implement a **voice-to-voice translation system** that:\n",
        "- Accepts **spoken English**\n",
        "- Transcribes speech to text\n",
        "- Translates text into multiple languages\n",
        "- Converts translated text back into **natural-sounding speech**\n",
        "- Supports **Godavari Telugu slang**, a regional dialect not supported by standard translators\n"
      ],
      "metadata": {
        "id": "o2yMPSZTO_U6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Selected Project Track\n",
        "\n",
        "**Track:**  \n",
        "‚úî Natural Language Processing (NLP)  \n",
        "‚úî Speech-to-Text (STT)  \n",
        "‚úî Text-to-Speech (TTS)  \n",
        "‚úî Applied AI System Design  \n",
        "\n",
        "This project integrates multiple AI subsystems into a single end-to-end pipeline.\n"
      ],
      "metadata": {
        "id": "NWUqg-1zPFe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# üîë SET YOUR KEYS HERE\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = \"YOUR_OPENROUTER_KEY\"\n",
        "os.environ[\"ELEVENLABS_API_KEY\"] = \"YOUR_ELEVENLABS_KEY\"\n",
        "os.environ[\"ELEVENLABS_VOICE_ID\"] = \"YOUR_VOICE_ID\"\n"
      ],
      "metadata": {
        "id": "YqshvIwNNBGP"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Problem Statement\n",
        "\n",
        "Existing translation systems:\n",
        "- Focus mainly on text\n",
        "- Lack support for regional dialects\n",
        "- Depend heavily on paid APIs\n",
        "- Are difficult to reproduce in academic environments\n",
        "\n",
        "This project aims to build a **fully reproducible, API-minimal, offline-capable** voice translation system suitable for academic evaluation.\n"
      ],
      "metadata": {
        "id": "q4CYbuCyPLGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Real-World Relevance & Motivation\n",
        "\n",
        "This system can be applied in:\n",
        "- Rural and regional communication systems\n",
        "- Assistive technologies\n",
        "- Language learning platforms\n",
        "- Call centers and customer support\n",
        "- Government and public service communication\n",
        "\n",
        "Motivation comes from the lack of support for **informal regional speech**, especially Indian dialects like Godavari Telugu.\n"
      ],
      "metadata": {
        "id": "ukbdqY0qPXjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Data Understanding & Preparation\n",
        "\n",
        "### Input Data\n",
        "- User-recorded audio via microphone (English speech)\n",
        "\n",
        "### Processing\n",
        "- Audio is directly passed to a speech recognition model\n",
        "- No pre-collected dataset is required\n",
        "- Real-time inference based system\n",
        "\n",
        "### Output Data\n",
        "- Translated text in multiple languages\n",
        "- Synthesized speech audio files\n"
      ],
      "metadata": {
        "id": "BAh4xktsPb5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "\n",
        "model = WhisperModel(\n",
        "    \"base\",\n",
        "    device=\"cpu\",   # change to \"cpu\" if no GPU\n",
        "    compute_type=\"int8\"\n",
        ")\n",
        "\n",
        "def transcribe_audio(audio_path: str) -> str:\n",
        "    segments, _ = model.transcribe(audio_path, language=\"en\")\n",
        "    return \" \".join(segment.text for segment in segments).strip()"
      ],
      "metadata": {
        "id": "rtARLeyQP5Cu"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Speech-to-Text Model\n",
        "\n",
        "We use **Whisper (faster-whisper)** for speech recognition due to:\n",
        "- High accuracy\n",
        "- Offline capability\n",
        "- Robustness to accents\n"
      ],
      "metadata": {
        "id": "_8tasNRSQBOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import Translator\n",
        "import requests, json\n",
        "\n",
        "LANGUAGES = [\"ru\", \"tr\", \"sv\", \"de\", \"es\", \"ja\"]\n",
        "\n",
        "def translate_multi(text):\n",
        "    outputs = []\n",
        "    for lang in LANGUAGES:\n",
        "        translator = Translator(from_lang=\"en\", to_lang=lang)\n",
        "        outputs.append(translator.translate(text))\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def english_to_godavari(text):\n",
        "    payload = {\n",
        "        \"model\": \"nex-agi/deepseek-v3.1-nex-n1:free\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are from Godavari Andhra Pradesh. \"\n",
        "                    \"Translate English to authentic Godavari Telugu slang. \"\n",
        "                    \"Use words like andi, masteru, thammu, babai, aaay.\"\n",
        "                )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY']}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        data=json.dumps(payload)\n",
        "    )\n",
        "\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
      ],
      "metadata": {
        "id": "PWXRraXrNFrl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Translation System Design\n",
        "\n",
        "### Multi-Language Translation\n",
        "Uses lightweight translation libraries for common languages.\n",
        "\n",
        "### Godavari Telugu Translation\n",
        "Handled using an LLM via OpenRouter, guided with a system prompt\n",
        "to generate **authentic regional slang**.\n"
      ],
      "metadata": {
        "id": "p4bWux-2QFmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "from elevenlabs import VoiceSettings\n",
        "from elevenlabs.client import ElevenLabs\n",
        "\n",
        "client = ElevenLabs(api_key=os.environ[\"ELEVENLABS_API_KEY\"])\n",
        "VOICE_ID = os.environ[\"ELEVENLABS_VOICE_ID\"]\n",
        "\n",
        "def text_to_speech(text):\n",
        "    response = client.text_to_speech.convert(\n",
        "        voice_id=VOICE_ID,\n",
        "        text=text,\n",
        "        model_id=\"eleven_multilingual_v2\",\n",
        "        output_format=\"mp3_22050_32\",\n",
        "        voice_settings=VoiceSettings(\n",
        "            stability=0.5,\n",
        "            similarity_boost=0.8,\n",
        "            style=0.5,\n",
        "            use_speaker_boost=True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    filename = f\"{uuid.uuid4()}.mp3\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        for chunk in response:\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "vx0YNM8kNH4L"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def voice_to_voice(audio_file):\n",
        "    text = transcribe_audio(audio_file)\n",
        "\n",
        "    translations = translate_multi(text)\n",
        "    godavari = english_to_godavari(text)\n",
        "\n",
        "    all_texts = translations + [godavari]\n",
        "    audio_outputs = [text_to_speech(t) for t in all_texts]\n",
        "\n",
        "    return (*audio_outputs, *all_texts)\n"
      ],
      "metadata": {
        "id": "bWXepn4-NLGf"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Core Implementation\n",
        "\n",
        "The complete pipeline:\n",
        "1. Audio Input\n",
        "2. Speech-to-Text\n",
        "3. Text Translation\n",
        "4. Text-to-Speech\n",
        "5. Output Audio + Text\n"
      ],
      "metadata": {
        "id": "mkl0iorqQaVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üéôÔ∏è English ‚Üí Multi-Language + Godavari Voice Translator\")\n",
        "\n",
        "    audio_input = gr.Audio(\n",
        "        sources=[\"microphone\"],\n",
        "        type=\"filepath\",\n",
        "        label=\"Speak in English\"\n",
        "    )\n",
        "\n",
        "    submit = gr.Button(\"Convert\")\n",
        "\n",
        "    audio_outputs = [\n",
        "        gr.Audio(label=l) for l in\n",
        "        [\"Russian\", \"Turkish\", \"Swedish\", \"German\", \"Spanish\", \"Japanese\", \"Godavari\"]\n",
        "    ]\n",
        "\n",
        "    text_outputs = [gr.Markdown() for _ in range(7)]\n",
        "\n",
        "    submit.click(\n",
        "        fn=voice_to_voice,\n",
        "        inputs=audio_input,\n",
        "        outputs=audio_outputs + text_outputs\n",
        "    )\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "iWtW27kNNNGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Evaluation & Analysis\n",
        "\n",
        "### Evaluation Criteria\n",
        "- Speech recognition accuracy\n",
        "- Translation coherence\n",
        "- Naturalness of synthesized speech\n",
        "- System robustness\n",
        "\n",
        "### Observations\n",
        "- Whisper performs well on clear speech\n",
        "- Godavari slang translation improves cultural relevance\n",
        "- TTS ensures stable output\n"
      ],
      "metadata": {
        "id": "942XiEF3QkgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Ethical Considerations & Responsible AI\n",
        "\n",
        "- No personal data is stored\n",
        "- Audio is processed locally\n",
        "- Avoids biased or harmful outputs\n",
        "- Transparency in model usage\n",
        "- No surveillance or misuse intent\n"
      ],
      "metadata": {
        "id": "7Am_lA2-Qv7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Conclusion & Future Scope\n",
        "\n",
        "### Conclusion\n",
        "This project demonstrates a practical, reproducible voice-to-voice translation system with regional dialect support.\n",
        "\n",
        "### Future Scope\n",
        "- Add Telugu native TTS\n",
        "- Language auto-detection\n",
        "- Mobile deployment\n",
        "- Larger dialect datasets\n"
      ],
      "metadata": {
        "id": "8bAOvV_AQ0G1"
      }
    }
  ]
}